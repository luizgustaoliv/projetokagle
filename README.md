# üöÄ Documenta√ß√£o - Predi√ß√£o de Sucesso de Startups

## üìã √çndice
- [Vis√£o Geral](#vis√£o-geral)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Requisitos](#requisitos)
- [Arquivos de Dados](#arquivos-de-dados)
- [Metodologia](#metodologia)
- [Funcionalidades do C√≥digo](#funcionalidades-do-c√≥digo)
- [Execu√ß√£o](#execu√ß√£o)
- [Resultados](#resultados)

---

## üéØ Vis√£o Geral

Este projeto foi desenvolvido para uma competi√ß√£o Kaggle que visa prever o sucesso de startups. O desafio simula um cen√°rio real onde uma aceleradora global busca otimizar seus investimentos identificando startups com maior probabilidade de sucesso.

### Objetivo
Criar um modelo de machine learning que preveja, com alta acur√°cia, se uma startup ser√° bem-sucedida, apoiando investidores e aceleradoras na tomada de decis√µes estrat√©gicas.

### Contexto dos Dados
A base cont√©m informa√ß√µes sobre:
- üìà **Hist√≥rico de capta√ß√£o de recursos**
- üåç **Localiza√ß√£o geogr√°fica**
- üè≠ **Setor de atua√ß√£o**
- üîó **Conex√µes estrat√©gicas**
- üèÜ **Marcos alcan√ßados**

---

## üìÅ Estrutura do Projeto

```
projeto/
‚îÇ
‚îú‚îÄ‚îÄ main.py                    # Script principal
‚îú‚îÄ‚îÄ train.csv                  # Dados de treinamento
‚îú‚îÄ‚îÄ test.csv                   # Dados de teste
‚îú‚îÄ‚îÄ sample_submission.csv      # Formato esperado de submiss√£o
‚îî‚îÄ‚îÄ submission.csv             # Arquivo gerado para submiss√£o
```

---

## üîß Requisitos

### Bibliotecas Necess√°rias

```python
numpy
pandas
scikit-learn
joblib
```

### Instala√ß√£o

```bash
pip install numpy pandas scikit-learn joblib
```

### ‚ö†Ô∏è Conformidade com Regras da Competi√ß√£o
Este c√≥digo utiliza **apenas bibliotecas permitidas**:
- ‚úÖ Numpy
- ‚úÖ Pandas
- ‚úÖ Scikit-learn
- ‚úÖ Joblib (parte do scikit-learn para paraleliza√ß√£o)

**M√©trica de avalia√ß√£o**: Acur√°cia (conforme regras da competi√ß√£o)

---

## üìä Arquivos de Dados

| Arquivo | Descri√ß√£o |
|---------|-----------|
| `train.csv` | Conjunto de treinamento com features e vari√°vel alvo (`labels`) |
| `test.csv` | Conjunto de teste sem a coluna alvo |
| `sample_submission.csv` | Modelo do formato de submiss√£o esperado |
| `submission.csv` | Arquivo final gerado com as predi√ß√µes |

---

## üß† Metodologia

### 1. **Engenharia de Features**

O c√≥digo implementa diversas t√©cnicas de feature engineering:

#### Features Derivadas
- **`age_first_last_diff`**: Diferen√ßa entre idade do √∫ltimo e primeiro financiamento
- **`missing_funding_total`**: Indicador bin√°rio de valores faltantes em funding
- **`log_funding_total`**: Transforma√ß√£o logar√≠tmica do funding total
- **`funding_per_round`**: Funding m√©dio por rodada de investimento
- **`has_milestones`**: Indicador bin√°rio de presen√ßa de milestones

#### Features de Intera√ß√£o
- **`funding_milestones_interaction`**: Intera√ß√£o entre funding por rodada e milestones
- **`log_funding_by_age_diff`**: Raz√£o entre log do funding e diferen√ßa de idade

#### Indicadores de Missing
Cria√ß√£o de flags para valores ausentes em colunas cr√≠ticas de idade/tempo.

### 2. **Pr√©-processamento**

#### Vari√°veis Num√©ricas
- Imputa√ß√£o: mediana
- Normaliza√ß√£o: StandardScaler

#### Vari√°veis Categ√≥ricas
- Imputa√ß√£o: moda (valor mais frequente)
- Codifica√ß√£o: OneHotEncoder com tratamento de categorias desconhecidas

### 3. **Modelagem**

#### Algoritmo Principal
**HistGradientBoostingClassifier** (Scikit-learn)

Caracter√≠sticas:
- Eficiente para grandes datasets
- Suporta valores missing nativamente
- Implementa√ß√£o otimizada de Gradient Boosting

#### Valida√ß√£o Cruzada
- **Estrat√©gia**: Stratified K-Fold (5 folds)
- **Objetivo**: Preservar distribui√ß√£o de classes e evitar overfitting

### 4. **Otimiza√ß√£o de Hiperpar√¢metros**

#### Grid Search Paralelizado
O c√≥digo implementa busca exaustiva **paralelizada** usando **joblib** nos seguintes hiperpar√¢metros:

| Hiperpar√¢metro | Valores Testados |
|----------------|------------------|
| `learning_rate` | [0.03, 0.05, 0.1] |
| `max_depth` | [4, 5, 6] |
| `max_leaf_nodes` | [63, 127] |
| `min_samples_leaf` | [3, 5, 10] |
| `l2_regularization` | [0.0, 0.1] |

**Total de combina√ß√µes testadas**: 3 √ó 3 √ó 2 √ó 3 √ó 2 = **108 configura√ß√µes**

#### Paraleliza√ß√£o
- Utiliza `Parallel(n_jobs=-1)` para usar todos os n√∫cleos da CPU
- Acelera drasticamente o grid search
- Cada combina√ß√£o √© avaliada independentemente

### 5. **Otimiza√ß√£o de Threshold**

Fun√ß√£o implementada **sem scipy** (conforme regras):

```python
def optimize_threshold_acc(y_true, y_probs):
    best_thresh = 0.5
    best_score = -1
    for t in np.linspace(0, 1, 101):
        preds = (y_probs >= t).astype(int)
        score = accuracy_score(y_true, preds)
        if score > best_score:
            best_score = score
            best_thresh = t
    return best_thresh
```

- Testa 101 thresholds entre 0 e 1
- Maximiza **acur√°cia** (m√©trica da competi√ß√£o)
- Implementa√ß√£o usando apenas numpy e sklearn

---

## ‚öôÔ∏è Funcionalidades do C√≥digo

### Fun√ß√£o: `load_data()`
```python
def load_data()
```
- Carrega os tr√™s arquivos CSV necess√°rios
- Valida exist√™ncia dos arquivos
- Retorna DataFrames de treino, teste e sample

### Fun√ß√£o: `basic_feature_engineering(df)`
```python
def basic_feature_engineering(df)
```
- Aplica transforma√ß√µes e cria novas features
- Calcula intera√ß√µes entre vari√°veis
- Gera indicadores de missing values
- Retorna DataFrame enriquecido

### Fun√ß√£o: `get_feature_lists(X)`
```python
def get_feature_lists(X)
```
- Identifica colunas num√©ricas e categ√≥ricas
- Retorna duas listas separadas por tipo

### Fun√ß√£o: `build_preprocessor(numeric_cols, cat_cols)`
```python
def build_preprocessor(numeric_cols, cat_cols)
```
- Cria pipeline de pr√©-processamento
- Configura transformadores para cada tipo de vari√°vel
- Retorna ColumnTransformer configurado

### Fun√ß√£o: `optimize_threshold_acc(y_true, y_probs)`
```python
def optimize_threshold_acc(y_true, y_probs)
```
- Busca threshold que maximiza **acur√°cia**
- Testa 101 valores linearmente espa√ßados
- Implementa√ß√£o sem depend√™ncias externas
- Retorna valor √≥timo de threshold

### Fun√ß√£o: `evaluate_combo(params, X, y, preprocessor, skf)`
```python
def evaluate_combo(params, X, y, preprocessor, skf)
```
- Avalia uma combina√ß√£o de hiperpar√¢metros
- Realiza valida√ß√£o cruzada completa (5 folds)
- Otimiza threshold para essa combina√ß√£o
- Retorna score, par√¢metros e threshold
- **Projetada para execu√ß√£o paralela**

### Fun√ß√£o: `main()`
```python
def main()
```
Orquestra todo o pipeline:
1. Carregamento de dados
2. Feature engineering
3. Pr√©-processamento
4. Grid search paralelizado com valida√ß√£o cruzada
5. Sele√ß√£o da melhor configura√ß√£o
6. Treinamento do modelo final
7. Gera√ß√£o de predi√ß√µes
8. Cria√ß√£o do arquivo de submiss√£o

---

## üöÄ Execu√ß√£o

### Passo a Passo

1. **Prepare os dados**
   ```bash
   # Certifique-se de que os arquivos est√£o no diret√≥rio:
   # - train.csv
   # - test.csv
   # - sample_submission.csv
   ```

2. **Execute o script**

   ```bash
   python main.py
   ```

3. **Acompanhe o progresso**
   - O joblib mostra progresso da paraleliza√ß√£o (verbose=10)
   - Tempo de execu√ß√£o: ~5-15 minutos (dependendo do hardware e n√∫mero de n√∫cleos)
   - Todas as 108 combina√ß√µes s√£o testadas em paralelo

4. **Submeta os resultados**
   - Arquivo gerado: `submission.csv`
   - Fa√ßa upload na plataforma Kaggle

### Exemplo de Sa√≠da

```
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.
[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.2min
[Parallel(n_jobs=-1)]: Done  108 out of 108 | elapsed:    8.5min finished
Melhor configura√ß√£o encontrada: (0.1, 6, 127, 3, 0.0) | Accuracy=0.8534 | threshold=0.420
Submission salvo em submission.csv | linhas=500 | threshold=0.420
```

---

## üìà Resultados

### M√©trica de Avalia√ß√£o
**Acur√°cia**: Propor√ß√£o de predi√ß√µes corretas sobre o total, conforme especificado nas regras da competi√ß√£o.

### Estrat√©gias Implementadas

‚úÖ **Feature Engineering robusto**
- Features derivadas capturando rela√ß√µes complexas
- Tratamento de missing values
- Transforma√ß√µes logar√≠tmicas

‚úÖ **Valida√ß√£o rigorosa**
- Stratified K-Fold para distribui√ß√£o balanceada
- Cross-validation para estimativa n√£o enviesada

‚úÖ **Otimiza√ß√£o completa e eficiente**
- Grid search em 108 combina√ß√µes
- **Paraleliza√ß√£o** para acelerar busca
- Threshold otimizado para maximizar acur√°cia

‚úÖ **Pipeline reprodut√≠vel**
- C√≥digo modular e organizado
- Random seeds fixas para reprodutibilidade
- Apenas bibliotecas permitidas pela competi√ß√£o

‚úÖ **Conformidade com regras**
- Sem uso de scipy ou bibliotecas n√£o autorizadas
- M√©trica correta (acur√°cia)
- Implementa√ß√µes customizadas quando necess√°rio

---
